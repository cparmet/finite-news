{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "931c9dd8-af02-4318-8bf3-67446fc8a35f",
   "metadata": {},
   "source": [
    "<img src=\"data:image/png;base64,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\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8021432a-564d-4e72-9085-500fbfb4b010",
   "metadata": {},
   "source": [
    "# Welcome to Finite News!\n",
    "This notebook creates and emails issues of Finite News."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8b8248-8001-4308-abed-ef4c4d644986",
   "metadata": {},
   "source": [
    "# Parameters for the notebook\n",
    "The constants below are used for developing and debugging. All other parameters for the newspaper are configured in the files on S3.  \n",
    "  \n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p><b>TO DEPLOY A NEW VERSION</b></p>\n",
    "    <ol>\n",
    "        <li>Set <code>DEV_MODE</code> & <code>DISABLE_GPT</code> to <code>FALSE</code>.</li>\n",
    "        <li>Create a new <a href=\"https://docs.aws.amazon.com/sagemaker/latest/dg/create-notebook-auto-run-studio.html\" target=\"_blank\">scheduled notebook job</a> on the Data Science 2.0 image with Python 3.8.</li>\n",
    "        <li>Delete the old notebook job.</li>\n",
    "        <li>Shut down the Sagemaker instance if it was used during development.</li>\n",
    "    </ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69927ffe-ffbd-4472-9df9-e26cac0940a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEV_MODE = False # True will not send email and not log newly fetched headlines for dedup later\n",
    "DISABLE_GPT = False # True will not call GPT API, so we don't incur costs while debugging\n",
    "LOGGING_LEVEL = \"warning\" # Logs end up in admin's news email. Use \"warning\" by default. Change to \"info\" to get more detailed logs for debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd609d66-2217-4f08-bab1-d01d770e2c0c",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0445b477-a51e-494f-8ed6-733a95c3637f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --quiet beautifulsoup4==4.10.0 boto3==1.33.9 botocore==1.33.9 openai==0.27.7 pandas==1.3.4 s3fs==0.4.2 sendgrid==6.10.0\n",
    "\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "from bs4 import BeautifulSoup\n",
    "from copy import deepcopy\n",
    "from datetime import date, datetime\n",
    "from io import StringIO\n",
    "import json\n",
    "import logging\n",
    "import openai\n",
    "import pandas as pd\n",
    "import pytz\n",
    "from random import choice\n",
    "import requests\n",
    "import s3fs\n",
    "fs = s3fs.S3FileSystem()\n",
    "from sendgrid import Attachment, SendGridAPIClient\n",
    "from sendgrid.helpers.mail import Mail\n",
    "from time import sleep\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daccdb53-a46c-40e0-a8d3-105856b027e9",
   "metadata": {},
   "source": [
    "# Functions\n",
    "To play nicely with Sagemaker scheduled notebooks (Papermill), all the code we need lives inside the notebook or is installed by the notebook. Papermill jobs cannot import local Python scripts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b025080-1156-49ba-99e1-bd4d00a47afd",
   "metadata": {},
   "source": [
    "## 📦 Loading\n",
    "Import data and initialize variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4294f7c7-888b-4ece-be99-0ed6064929f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def init_logging(logging_level):\n",
    "    \"\"\"Initialize logging to in-memory object, for optional delivery in admin's issue of Finite News.\n",
    "    \n",
    "    NOTE\n",
    "    Reminder: This function doesn't reset an active log. Must restart the kernel in SageMaker.\n",
    "    \n",
    "    ARGUMENTS\n",
    "    logging_level (str): The granularity of logging messages, 'warning' or 'info'\n",
    "    \n",
    "    RETURNS\n",
    "    log_stream (StringIO object): In-memory file-like object that collects results from logging during the Finite News run\n",
    "    \"\"\"\n",
    "    \n",
    "    log_stream = StringIO() \n",
    "    if logging_level=='warning':\n",
    "        level = logging.WARNING\n",
    "    elif logging_level=='info':\n",
    "        level = logging.INFO\n",
    "    logging.basicConfig(stream=log_stream, level=level)\n",
    "    return log_stream\n",
    "\n",
    "\n",
    "def get_fn_secret(secret_key, secret_name=\"fn_secrets\", region_name=\"us-east-1\"):\n",
    "    \"\"\"Retrieve a secret from AWS Secrets Manager.\n",
    "    \n",
    "    ARGUMENTS\n",
    "    secret_key (string): the specific secret to retrieve, such as BUCKET_PATH or OPENAI_API_KEY\n",
    "    secret_name (string): the group where the Finite News secrets are stored in AWS Secrets Manager\n",
    "    region_name (string): the region where your AWS Secrets Manager secret_name lives. See the sample code provided by Secrets Manager after you create the secret\n",
    "\n",
    "    RETURNS\n",
    "    secret_value (string): the secret!\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a Secrets Manager client\n",
    "    session = boto3.session.Session()\n",
    "    client = session.client(\n",
    "        service_name='secretsmanager',\n",
    "        region_name=region_name\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        get_secret_value_response = client.get_secret_value(\n",
    "            SecretId=secret_name\n",
    "        )\n",
    "    except ClientError as e: # Stop the presses, we can't get our secret.\n",
    "        raise e\n",
    "\n",
    "    # Decrypt secret using the associated KMS key.\n",
    "    try:\n",
    "        return json.loads(get_secret_value_response[\"SecretString\"])[secret_key]\n",
    "    except KeyError as e:\n",
    "        raise KeyError(f\"Secret key {str(e)} not found. Is it stored in AWS Secrets Manager? Have you given permissions for your SageMaker user to access the secret?\") # No sense in logging the exception since we won't be sending any emails (where we store logs)\n",
    "        \n",
    "\n",
    "def load_assets_from_s3(bucket_path):\n",
    "    \"\"\"Import assets from S3 for the publication in general.\n",
    "\n",
    "    ARGUMENTS\n",
    "    bucket_path (str): The location of the S3 bucket where required files are stored.\n",
    "\n",
    "    RETURNS\n",
    "    thoughts_of_the_day (list): Jokes and quotes\n",
    "    substance_rules (dict): Logic for dropping headlines of little substance\n",
    "    template_html (str): The HTML layout of a Finite News issue\n",
    "    \"\"\"\n",
    "\n",
    "    # List of quotes from which to sample a Thought for the Day\n",
    "    try:\n",
    "        with fs.open(bucket_path + \"thoughts_of_the_day.yml\") as f:\n",
    "            thoughts_of_the_day = yaml.load(f, Loader=yaml.Loader)[\"quotes\"]\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"Couldn't load thoughts_of_the_day.yml. load_assets_from_s3() error: {str(type(e))}, {str(e)}\")\n",
    "\n",
    "    # Text rules for filtering out headlines\n",
    "    try:\n",
    "        with fs.open(bucket_path + \"substance_rules.yml\") as substance_rules_file:\n",
    "            substance_rules = yaml.load(substance_rules_file, Loader=yaml.Loader)\n",
    "    except Exception as e:\n",
    "        logging.critical(f\"Couldn't load substance_rules.yml. load_assets_from_s3() error: {str(type(e))}, {str(e)}\")\n",
    "\n",
    "    # Template for the email\n",
    "    try:\n",
    "        with fs.open(bucket_path + \"template.htm\", \"r\") as f:\n",
    "            template_html = f.read()\n",
    "    except Exception as e:\n",
    "        logging.critical(f\"Couldn't load template.htm. load_assets_from_s3() error: {str(type(e))}, {str(e)}\")\n",
    "        raise\n",
    "    \n",
    "    return thoughts_of_the_day, substance_rules, template_html\n",
    "\n",
    "\n",
    "def load_publication_config(\n",
    "    publication_config_file_name=\"publication_config.yml\",\n",
    "    dev_mode=False,\n",
    "    disable_gpt=False\n",
    "):\n",
    "    \"\"\"Import general settings and assets from files on S3, used for all subscribers\n",
    "    \n",
    "    ARGUMENTS\n",
    "    publication_config_file_name (str): file name for the general publication parameters YML file in the S3 bucket identified by BUCKET_PATH\n",
    "    dev_mode (bool): If True we're in development or debug mode, so don't send emails or modify headline_logs.\n",
    "    disable_gpt (bool): If True, don't call the GPT API and incur costs, for example during dev or debug cycles.\n",
    "    \n",
    "    RETURNS\n",
    "    publication_config (dict): General settings for today's run of Finite News, that apply to all issues / subscribers \n",
    "    \"\"\"\n",
    "    \n",
    "    bucket_path = get_fn_secret(\"BUCKET_PATH\")\n",
    "\n",
    "    # Load publication settings\n",
    "    with fs.open(bucket_path + publication_config_file_name) as publication_config_file:\n",
    "        publication_config = yaml.load(publication_config_file, Loader=yaml.Loader)\n",
    "    \n",
    "    # Add shared assets\n",
    "    thoughts_of_the_day, substance_rules, template_html = load_assets_from_s3(bucket_path)\n",
    "    # Populate config dictionary\n",
    "    return {\n",
    "        \"bucket_path\": bucket_path,\n",
    "        \"email_delivery\": not dev_mode, # If dev_mode is True, don't send emails\n",
    "        \"sender\": publication_config[\"sender\"],\n",
    "        \"layout\": {\n",
    "            \"template_html\": template_html,\n",
    "            \"logo_url\": publication_config[\"layout\"][\"logo_url\"],\n",
    "        },\n",
    "        \"editorial\": {\n",
    "            \"one_headline_keywords\": publication_config[\"editorial\"][\"one_headline_keywords\"],\n",
    "            \"substance_rules\": substance_rules,\n",
    "            \"log_today_headlines\": False if dev_mode else True,\n",
    "        },\n",
    "        \"nws\" : publication_config[\"nws\"],\n",
    "        \"gpt\": publication_config.get(\"gpt\", None) if not disable_gpt else None,\n",
    "        \"news_sources\": publication_config[\"news_sources\"],\n",
    "        \"arts_sources\": publication_config[\"arts_sources\"],\n",
    "        \"thoughts_of_the_day\": thoughts_of_the_day,\n",
    "    }\n",
    "\n",
    "\n",
    "def get_subscriber_list(bucket_path, folder_name=\"finite_files\"):\n",
    "    \"\"\"Find the subscribers (the names of their config files) on the Finite News bucket.\n",
    "    \n",
    "    ARGUMENTS\n",
    "    bucket_path (str): The location of the S3 bucket where required files are stored.\n",
    "    folder_name (str): The part of the path that contains the folder on the bucket, if present. Used to remove from .\n",
    "    \n",
    "    NOTE: \n",
    "    1. Assumes the folder is at the root of the bucket. If it's nested, use relative path up to root.\n",
    "    2. Assumes all files in the folder that begin with \"config_\" are a subscriber config file.\n",
    "    \n",
    "    RETURNS\n",
    "    subscriber_config_file_names (list): yml file names in finite bucket\n",
    "    \"\"\"\n",
    "    \n",
    "    fn_bucket = (\n",
    "        boto3\n",
    "        .resource(\"s3\")\n",
    "        .Bucket(\n",
    "            bucket_path\n",
    "            .split(\"//\")\n",
    "            [1]\n",
    "            .split(\"/\")\n",
    "            [0]\n",
    "        )\n",
    "    )\n",
    "    # Iterate through files on the bucket and select those that begin with config_\n",
    "    return [\n",
    "        f.key.replace(f\"{folder_name}/\", \"\")\n",
    "        for f in fn_bucket.objects.filter(Prefix=f\"{folder_name}/\")\n",
    "        if f.key.startswith(f\"{folder_name}/config_\")\n",
    "    ]\n",
    "\n",
    "\n",
    "def personalize_gpt_instruction(instruction, nba_teams=None):\n",
    "    \"\"\"Customize the instructions we give GPT for editing headlines, depending on the subscriber's preferences\n",
    "\n",
    "    ARGUMENTS\n",
    "    instruction (str): The current GPT instruction text, including the placeholder {NBA_EXCLUSION}\n",
    "    nba_teams (list): The names of NBA teams the subscriber is tracking\n",
    "    \n",
    "    RETURNS\n",
    "    instruction (str): Updated instruction that tells GPT not to remove those NBA headlines\n",
    "    \"\"\"\n",
    "    \n",
    "    nba_base = \"Don't list a headline if it mentions \"\n",
    "    if len(nba_teams)==1:\n",
    "        nba_exclusion = nba_base + f\"'the {nba_teams[0]}'. \"\n",
    "    elif len(nba_teams)>1:\n",
    "        nba_exclusion = nba_base + \" or \".join([f\"'the {team}'\" for team in nba_teams]) + \". \"\n",
    "    else: # No NBA teams tracked, so we'll just cut the placeholder {NBA_EXCLUSION} from instruction.\n",
    "        nba_exclusion = \"\"\n",
    "    return instruction.replace(\"{NBA_EXCLUSION}\", nba_exclusion)\n",
    "\n",
    "\n",
    "def load_subscriber_config(subscriber_config_file_name, publication_config):\n",
    "    \"\"\"Import subscriber-specific parameters and combine with general publication settings\n",
    "    \n",
    "    ARGUMENTS\n",
    "    subscriber_config_file_name (str): name of the subscriber's config YML file in the S3 bucket\n",
    "    publication_config (dict): loaded general publication parameters\n",
    "    \n",
    "    RETURNS\n",
    "    issue (dict): Settings for an issue, combining subscriber and general publication parameters\n",
    "    \"\"\"\n",
    "    \n",
    "    issue = deepcopy(publication_config) # Copy dict with nested dicts\n",
    "    with fs.open(issue[\"bucket_path\"] + subscriber_config_file_name) as subscriber_config_file:\n",
    "        subscriber_config = yaml.load(subscriber_config_file, Loader=yaml.Loader)\n",
    "    issue[\"admin\"] = subscriber_config.get(\"admin\", False)\n",
    "    issue[\"subscriber_email\"] = subscriber_config[\"email\"]\n",
    "\n",
    "    issue[\"editorial\"][\"add_car_talk_credit\"] = subscriber_config[\"editorial\"].get(\"add_car_talk_credit\", False)\n",
    "    issue[\"editorial\"][\"last_headlines_path\"] = \"\"\n",
    "    if \"editorial\" in subscriber_config:\n",
    "        if \"last_headlines_file\" in subscriber_config[\"editorial\"]:\n",
    "            issue[\"editorial\"][\"last_headlines_path\"] = issue[\"bucket_path\"] + subscriber_config[\"editorial\"][\"last_headlines_file\"]\n",
    "    if issue[\"editorial\"][\"last_headlines_path\"] == \"\":\n",
    "        logging.warning(\"No last_headlines_path. Not logging/updating yesterday's headlines\")\n",
    "    \n",
    "    issue[\"arts_sources\"] = publication_config[\"arts_sources\"] if subscriber_config[\"sources\"][\"add_arts_headlines\"] else []\n",
    "    issue[\"nba_teams\"] = subscriber_config.get(\"nba_teams\", None)\n",
    "    issue[\"nws\"][\"office\"] = subscriber_config[\"nws\"][\"office\"] # Add by element because publication_config has NWS already\n",
    "    issue[\"nws\"][\"grid_x\"] = subscriber_config[\"nws\"][\"grid_x\"]\n",
    "    issue[\"nws\"][\"grid_y\"] = subscriber_config[\"nws\"][\"grid_y\"]\n",
    "    issue[\"nws\"][\"location_name\"] = subscriber_config[\"nws\"][\"location_name\"]\n",
    "    issue[\"slogans\"] = subscriber_config[\"slogans\"]\n",
    "    issue[\"thoughts_of_the_day\"] = subscriber_config[\"thoughts_of_the_day\"] + publication_config[\"thoughts_of_the_day\"] if subscriber_config[\"editorial\"].get(\"add_shared_thoughts\", False) else subscriber_config[\"thoughts_of_the_day\"]\n",
    "    return issue\n",
    "\n",
    "\n",
    "def load_subscriber_configs(dev_mode, disable_gpt):\n",
    "    \"\"\"Create the config file needed to generate each issue, combining publication and subscriber settings.\n",
    "    \n",
    "    ARGUMENTS\n",
    "    dev_mode (bool): If True we're in development or debug mode, so don't send emails or modify headline_logs.\n",
    "    disable_gpt (bool): If True, don't call the GPT API and incur costs, for example during dev or debug cycles.\n",
    "\n",
    "    RETURNS\n",
    "    subscriber_configs (list): issue_config for each subscriber we need to generate an issue for\n",
    "    \"\"\" \n",
    "    \n",
    "    publication_config = load_publication_config(dev_mode=dev_mode, disable_gpt=disable_gpt)    \n",
    "    subscriber_list = get_subscriber_list(publication_config[\"bucket_path\"])\n",
    "    subscriber_configs = [\n",
    "        load_subscriber_config(subscriber_config_file_name, publication_config)\n",
    "        for subscriber_config_file_name in subscriber_list\n",
    "    ]\n",
    "    # Sort subscribers so the \"admins\" go last. \n",
    "    # Allows the admin email issue(s) to include logging warnings from the non-admin issues.\n",
    "    subscriber_configs = sorted(subscriber_configs , key=lambda x: x[\"admin\"]) \n",
    "    return subscriber_configs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf9d023-4383-4387-a634-46f3fa7efd0e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 🕵🏻‍♀️ Reporting\n",
    "Research the day's news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1606caec-a534-447a-a333-6f0c35d9bc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_headlines(source):\n",
    "    \"\"\"Use a tag scraper to fetch a source's headlines\n",
    "    \n",
    "    TODO: Refactor to simplify. Separate if then for get_text vs get_text + split_char.\n",
    "    \n",
    "    ARGUMENTS\n",
    "    source (dict): Description of the website to scrape\n",
    "    \n",
    "    RETURNS\n",
    "    headlines (list of str): Headlines retrieved\n",
    "    \n",
    "    \"\"\"\n",
    "    response = requests.get(source[\"url\"])\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    if \"select_query\" in source:\n",
    "        headlines = soup.select(source[\"select_query\"])\n",
    "        headlines = [headline.contents[0] for headline in headlines]\n",
    "    elif \"tag_class\" in source:\n",
    "        headlines = soup.find_all(source[\"tag\"], {\"class\":source[\"tag_class\"]})\n",
    "        if \"tag_next\" and \"split_char\" in source:\n",
    "            headlines = headlines[0].findNext(source[\"tag_next\"]).get_text()\n",
    "            headlines = [headline for headline in headlines.split(source[\"split_char\"]) if headline]\n",
    "        else:\n",
    "            headlines = [headline.contents[0] for headline in headlines]\n",
    "    else:\n",
    "        headlines = soup.find_all(source[\"tag\"])\n",
    "        headlines = [headline.get_text() for headline in headlines]\n",
    "    if \"min_words\" in source:\n",
    "        headlines = [headline for headline in headlines if count_words(headline)>=source[\"min_words\"]] # Have seen some that are just \"Advertisement\", or author names\n",
    "    headlines = list(set(headlines)) # De-dup\n",
    "    return headlines\n",
    "\n",
    "\n",
    "def call_api_for_headlines(source):\n",
    "    \"\"\"Use an API to fetch a source's headlines. \n",
    "\n",
    "    NOTE\n",
    "        - Requires that the API key named in the source config file is stored in AWS Secrets Manager.\n",
    "        - Assumes API response comes back in JSON format.\n",
    "\n",
    "    ARGUMENTS\n",
    "    source (dict): Description of the API to call and parse\n",
    "    \n",
    "    RETURNS\n",
    "    headlines (list of str): Headlines retrieved\n",
    "        \n",
    "    \"\"\"\n",
    "    response = requests.get(source[\"url\"] + get_fn_secret(source[\"api_key_name\"]))\n",
    "    results = response.json()[\"results\"]\n",
    "    headlines = [article[source[\"headline_field\"]] for article in results]\n",
    "    return headlines\n",
    "\n",
    "\n",
    "def get_todays_nba_game(team_name):\n",
    "    \"\"\"Call the NBA API to find out if a team is playing today.\n",
    "    \n",
    "    NOTE\n",
    "    This updated version accounts for the limitation of using the NBA API's current day's scoreboard: \n",
    "    the scoreboard isn't always updated until a certain hour in the morning, after FN may be run.\n",
    "    The updated approach here looks at the whole year's schedule, including post-season. Adapted from : https://github.com/swar/nba_api/issues/296\n",
    "\n",
    "    TODO: Clean and simpify. No need to use Pandas.\n",
    "    \n",
    "    ARGUMENTS:\n",
    "    team_name (str): NBA team such as \"Celtics\" or \"Lakers\"\n",
    "    \n",
    "    RETURNS\n",
    "    message (str or None): A headline-style update if the team is playing tonight.\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        url = 'https://cdn.nba.com/static/json/staticData/scheduleLeagueV2.json'\n",
    "        r = requests.get(url)\n",
    "        schedule = r.json()\n",
    "        schedule = schedule['leagueSchedule']['gameDates']\n",
    "        games = []\n",
    "        for gameday in schedule:\n",
    "            for game in gameday['games']:\n",
    "                game_details = [\n",
    "                        game['gameDateTimeUTC'],\n",
    "                        game['homeTeam']['teamName'],\n",
    "                        game['homeTeam']['teamCity'],\n",
    "                        game['awayTeam']['teamName'],\n",
    "                        game['awayTeam']['teamCity'],\n",
    "                       ]\n",
    "                game_details = pd.DataFrame(\n",
    "                    [game_details],\n",
    "                    columns =[\n",
    "                        \"gameDateTimeUTC\",\n",
    "                        \"homeTeam\",\n",
    "                        \"homeCity\",\n",
    "                        \"awayTeam\",\n",
    "                        \"awayCity\",\n",
    "                    ]\n",
    "                )\n",
    "                games.append(game_details)\n",
    "        games = pd.concat([game for game in games])\n",
    "\n",
    "        eastern = pytz.timezone('US/Eastern')\n",
    "        games['gameDateTimeUTC'] = pd.to_datetime(games['gameDateTimeUTC'], errors='coerce')\n",
    "        games = games.dropna(subset=['gameDateTimeUTC'])\n",
    "        games['gameDateTimeEastern'] = games['gameDateTimeUTC'].apply(lambda t: t.astimezone(eastern))\n",
    "        games['gameDate'] = games['gameDateTimeEastern'].apply(lambda d: d.date())\n",
    "\n",
    "        game = (\n",
    "            games.loc[\n",
    "                ((games['awayTeam'] == team_name) | (games['homeTeam'] == team_name))\n",
    "                & (games['gameDate'] == datetime.today().date())]\n",
    "        )\n",
    "        if game.shape[0]==1:\n",
    "            game = game.iloc[0]\n",
    "            tipoff = game[\"gameDateTimeEastern\"].strftime(\"%I:%M\").lstrip(\"0\").replace(\":00\",\"\")\n",
    "            if team_name in game[\"homeTeam\"]:\n",
    "                other_team = game[\"awayTeam\"]\n",
    "                message = f\"The {team_name} host the {other_team} at {tipoff}.\"\n",
    "            else:\n",
    "                other_city = game[\"homeCity\"]\n",
    "                message = f\"The {team_name} are in {other_city}. Tipoff at {tipoff}.\"\n",
    "        else:\n",
    "            message=None\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"NBA game error for {team_name}: {str(type(e))}, {str(e)}\")\n",
    "        message= None\n",
    "    return message\n",
    "\n",
    "\n",
    "def download_headlines(source):\n",
    "    \"\"\"Fetch a source's desired content from the Internet.\n",
    "\n",
    "    ARGUMENTS\n",
    "    source (dict): Description of the API to call or website to scrape\n",
    "    \n",
    "    RETURNS\n",
    "    headlines (list of str): Headlines retrieved\n",
    "    \"\"\"\n",
    "    \n",
    "    if source[\"method\"]==\"api\":\n",
    "        return call_api_for_headlines(source)\n",
    "    if source[\"method\"]==\"scrape\":\n",
    "        return scrape_headlines(source)\n",
    "    \n",
    "\n",
    "def research_headlines(source, max_headlines):\n",
    "    \"\"\"Download headlines from a source then post-process each source's list. \n",
    "\n",
    "    NOTE\n",
    "    See also clean_headline() for post-processing that's done on the level of an individual headline.\n",
    "    \n",
    "    ARGUMENTS\n",
    "    source (dict): Description of the API to call or website to scrape\n",
    "    max_headlines (int): The upper limit on how many headlines we will take from this source\n",
    "    \n",
    "    RETURNS\n",
    "    headlines (list of str): Headlines from the source, after postprocessing\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get those headlines\n",
    "    headlines = download_headlines(source)\n",
    "    \n",
    "    # Lightly postprocess 'em\n",
    "    if headlines:\n",
    "        headlines = [headline.strip() for headline in headlines if headline]\n",
    "        if max_headlines:\n",
    "            headlines = headlines[0:max_headlines]\n",
    "    return headlines\n",
    "  \n",
    "    \n",
    "def research_source(source):\n",
    "    \"\"\"Download a source's content then post-process.\n",
    "\n",
    "    ARGUMENTS\n",
    "    source (dict): Description of the API to call or website to scrape\n",
    "\n",
    "    RETURNS\n",
    "    source (dict): Dictionary with new key \"headlines\" (list of str)\n",
    "\n",
    "    \"\"\"\n",
    "    if source[\"type\"]==\"headlines\":\n",
    "        source[\"headlines\"] = research_headlines(\n",
    "            source=source, \n",
    "            max_headlines=source.get(\"max_headlines\", None)\n",
    "        )\n",
    "    if len(source['headlines'])==0 and not source.get(\"exclude_from_0_results_warning\", False): # Escalate to admin if no results were returned, and that was unexpected. Source's scraper/API may be broken.\n",
    "        logging.warning(f\"{source['name']}: retrieved 0 headlines\") \n",
    "    else:\n",
    "        logging.info(f\"{source['name']}: retrieved {len(source['headlines'])} headlines\")\n",
    "    return source\n",
    "\n",
    "\n",
    "def research_sources(sources):\n",
    "    \"\"\"Get content from multiple sources, through various means, and post-process.\n",
    "    \n",
    "    ARGUMENTS\n",
    "    sources (list of dict): A list of sources to get headlines from\n",
    "    \n",
    "    RETURNS\n",
    "    sources (dict): List of source description dictionaries with new key \"headlines\" (list of str)\n",
    "    \"\"\"\n",
    "    \n",
    "    sources = [research_source(source) for source in sources]\n",
    "    return sources\n",
    "\n",
    "\n",
    "def get_forecast(nws_config):\n",
    "    \"\"\"Use National Weather Service API to get local forecast.\n",
    "        \n",
    "    ARGUMENTS\n",
    "    nws_config (dict): Parameters for calling the NWS API, including keys for:\n",
    "        - office (str): Which NWS office to get the forecast from (See NOTE above)\n",
    "        - grid_x (int), grid_y (int): Coordinates for the forecast (See NOTE above)\n",
    "        - location_name (str): Town or city name (no state/country etc)\n",
    "        - api_snooze_bar (int): How many seconds to wait before retrying NWS after an exception\n",
    "\n",
    "    RETURNS\n",
    "    forecast (dict or None): Attributes of the forecast retrieved, or None if there was a problem.\n",
    "    \"\"\"\n",
    "    \n",
    "    MAX_ATTEMPTS = 10 \n",
    "    try:\n",
    "        attempts=1\n",
    "        while attempts<MAX_ATTEMPTS:\n",
    "            url =f\"https://api.weather.gov/gridpoints/{nws_config['office']}/{nws_config['grid_x']},{nws_config['grid_y']}/forecast\"\n",
    "            r = requests.get(url, timeout=5)\n",
    "            if r.status_code==200:\n",
    "                break\n",
    "            else:\n",
    "                attempts+=1\n",
    "                logging.info(f\"Weather request {r.status_code}. Wait {nws_config['api_snooze_bar']} seconds and retry, take # {attempts} ...\")\n",
    "                sleep(10)\n",
    "        \n",
    "        result = r.json()[\"properties\"][\"periods\"][0]\n",
    "        forecast = {\n",
    "            \"short\": result.get(\"shortForecast\", None),\n",
    "            \"detailed\": result.get(\"detailedForecast\", None),\n",
    "            \"icon_url\": result.get(\"icon\", None)\n",
    "        }\n",
    "        forecast[\"short\"] = forecast[\"short\"].capitalize() # Change from Title Case to Sentence case \n",
    "        if nws_config[\"location_name\"]:\n",
    "            forecast[\"short\"] += f\" in {nws_config['location_name']}\"\n",
    "        return forecast\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"Forecast error after {MAX_ATTEMPTS} attempts: {str(type(e))}, {str(e)}, {r}\")\n",
    "        return None\n",
    "    \n",
    "\n",
    "def get_weather_emoji(forecast):\n",
    "    \"\"\"\n",
    "    Label a weather forecast with an emoji. It's used to spice up the section header.\n",
    "    \n",
    "    ARGUMENTS\n",
    "    forecast (dict): Attributes of the forecast retrieved.\n",
    "    \n",
    "    RETURNS\n",
    "    emoji (str): One character\n",
    "    \"\"\"\n",
    "\n",
    "    forecast = forecast.lower()\n",
    "    if \"tornado\" in forecast:\n",
    "        return \"🌪️\"\n",
    "    if \"hurricane\" in forecast:\n",
    "        return \"🌀\"\n",
    "    if \"thunder\" in forecast or \"lightning\" in forecast:\n",
    "        return \"⚡\"\n",
    "    if \"snow\" in forecast or \"flurries\" in forecast:\n",
    "        return \"❄️\"\n",
    "    if \"rain\" in forecast or \"pour\" in forecast or \"shower\" in forecast or \"drizzle\" in forecast: # Must come after snow for snow showers\n",
    "        return \"☔\"\n",
    "    if \"hot\" in forecast:\n",
    "        return \"🥵\"\n",
    "    if \"freezing\" in forecast:\n",
    "        return \"🥶\"\n",
    "    if \"partly cloudy\" in forecast or \"mostly sunny\" in forecast:\n",
    "        return \"🌤️\"\n",
    "    if \"sunny\" in forecast or \"beautiful\" in forecast or \"warm\" in forecast: # Must come after mostly sunny\n",
    "        return \"😎\"\n",
    "    if \"mostly cloudy\" in forecast:\n",
    "        return \"🌥️\"\n",
    "    if \"cloudy\" in forecast:\n",
    "        return \"☁️\"\n",
    "    if \"windy\" in forecast:\n",
    "        return \"🌬️\"\n",
    "    return \"🔮\"\n",
    "\n",
    "\n",
    "def get_screenshots(sources):\n",
    "    \"\"\"Not currently working on SM. Disabled.\"\"\"\n",
    "    if not sources:\n",
    "        return []\n",
    "    options = Options()\n",
    "    options.add_argument('headless')\n",
    "    s=Service(ChromeDriverManager().install())\n",
    "    driver = webdriver.Chrome(service=s, options=options)\n",
    "    driver.maximize_window()\n",
    "\n",
    "    screenshots = []\n",
    "    for source in sources:\n",
    "        url = source[\"url\"]\n",
    "        driver.get(url)\n",
    "        try:\n",
    "            elements = driver.find_elements(By.CLASS_NAME, source[\"element_class\"])\n",
    "            if source.get(\"automate_gradually\", False):\n",
    "            # TODO: Temporary workaround for Birdcast. There's surely a better way\n",
    "                b64_screenshots = [element.screenshot_as_base64 for element in elements]\n",
    "                screenshot_b64 = b64_screenshots[source[\"element_number\"]]\n",
    "            else:       \n",
    "                # The simpler way that should work for nondynamically loaded images\n",
    "                chart_element = elements[source[\"element_number\"]]\n",
    "                screenshot_b64 = chart_element.screenshot_as_base64\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Selenium error on {source['url']}: {str(type(e))}, {str(e)}\")\n",
    "        screenshots.append(screenshot_b64)\n",
    "        driver.quit()\n",
    "    return screenshots\n",
    "\n",
    "\n",
    "def get_attributions(headline_sources, nba_used, nws_used):\n",
    "    \"\"\"Compile the names of all sources used in the issue, to give credit.\n",
    "    \n",
    "    ARGUMENTS\n",
    "    headline_sources (list of dict): A list of sources we tried to get headlines from\n",
    "    nba_used (bool): True if the issue tracks an NBA team\n",
    "    nws_used (bool): True if we were got a local forecast\n",
    "    \n",
    "    RETURNS\n",
    "    attributions (list of str): The names of the sources\n",
    "    \"\"\"\n",
    "    \n",
    "    attributions = list(set([source[\"name\"] for source in headline_sources])) # De-dups\n",
    "    attributions += [\"Car Talk credits\"]\n",
    "    if nba_used: attributions+= [\"NBA API\"]\n",
    "    if nws_used: attributions+= [\"National Weather Service\"]\n",
    "    attributions = sorted(attributions)\n",
    "    return \", \".join(attributions)\n",
    "\n",
    "\n",
    "def get_car_talk_credit(bucket_path):\n",
    "    \"\"\"Pull a random Car Talk credit from a CSV on S3. \n",
    "    \n",
    "    NOTE\n",
    "    - These credits are fake staff credits that were used at the end of each episode of\n",
    "    the National Public Radio automotive advice radio show, Car Talk\n",
    "    - They came from downloading https://www.cartalk.com/content/staff-credits.\n",
    "\n",
    "    ARGUMENTS \n",
    "    bucket_path (str): The location of the S3 bucket where required files are stored.\n",
    "\n",
    "    RETURNS\n",
    "    car_talk_credit (str): A fake staff member to thank for creation of this issue of Finite News :D\n",
    "    \"\"\"\n",
    "    \n",
    "    return \": \".join(\n",
    "        pd.read_csv(bucket_path + \"car_talk_credits.csv\", header=None)\n",
    "        .sample(1)\n",
    "        .values\n",
    "        .flatten()\n",
    "        .tolist()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c04717-5c9c-4642-b14f-01fcb6dfab8b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ✂️ Editorial\n",
    "Refine the news and other reporting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be71e6ef-d792-49f6-a5d9-ead256585180",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(text):\n",
    "    \"\"\"Helper function to count how many words are in a string.\n",
    "    \n",
    "    TODO: Use a tokenizer/built-in\n",
    "    \n",
    "    ARGUMENTS\n",
    "    text (str)\n",
    "    \n",
    "    RETURNS\n",
    "    count (int)\n",
    "    \"\"\"\n",
    "    \n",
    "    return len(text\n",
    "               .strip()\n",
    "               .split(\" \"))\n",
    "\n",
    "\n",
    "def log_headlines(headlines, last_headlines_path):\n",
    "    \"\"\"Export a list of today's headlines, so we can use them to de-dup tomorrow's news.\n",
    "    \n",
    "    NOTE: Must call this before edit_research so we carry forward repeats that were dropped too\n",
    "\n",
    "    ARGUMENTS\n",
    "    headlines (list of str): Headlines from all sources\n",
    "    last_headlines_path (str): The full path on S3 for this subscriber's cache of yesterday's headlines\n",
    "\n",
    "    RETURNS\n",
    "    None\n",
    "    \"\"\"\n",
    "    \n",
    "    with fs.open(last_headlines_path, \"w\") as cache_file:\n",
    "        for headline in headlines:\n",
    "            cache_file.write(f\"{headline}\\n\")\n",
    "        logging.info(f\"Wrote last headlines to {last_headlines_path}\")\n",
    "            \n",
    "\n",
    "def apply_one_headline_keyword_filter(headlines, keyword):\n",
    "    \"\"\"Cap headlines mentioning this keyword.\n",
    "\n",
    "    ARGUMENTS\n",
    "    headlines (list of str): Headlines from all sources\n",
    "\n",
    "    RETURNS\n",
    "    new_headlines (list of str): Headlines except those that contain this keyword\n",
    "    \"\"\"\n",
    "    \n",
    "    new_headlines = []\n",
    "    kw_counter = 0\n",
    "    keyword = keyword.lower()\n",
    "    for headline in headlines:\n",
    "        has_kw = keyword in headline.lower() # Could add spaCy tokenizer, split on spaces, punctuation. But the benefit would be teeny. Empirically this has been working perfectly for months.\n",
    "        kw_counter += has_kw\n",
    "        if not has_kw or kw_counter<=1:\n",
    "            new_headlines.append(headline)\n",
    "    return new_headlines\n",
    "\n",
    "\n",
    "def limit_one_headline_keywords(headlines, keywords):\n",
    "    \"\"\"Apply user's policy to have a maximum of one article with each keyword in a singles issue.\n",
    "    \n",
    "    ARGUMENTS\n",
    "    headlines (list of str): Headlines from all sources\n",
    "    keywords (list of str): Keywords that should appear in the issue at most one time\n",
    "    \n",
    "    RETURNS\n",
    "    new_headlines (list of str): Headlines except those cut for containing keywords already reported on once\n",
    "\n",
    "    \"\"\"\n",
    "    for keyword in keywords:\n",
    "        headlines = apply_one_headline_keyword_filter(headlines, keyword)\n",
    "    return headlines\n",
    "\n",
    "\n",
    "def remove_repeat_headlines(headlines, last_headlines_path):\n",
    "    \"\"\"Don't present a headline if it was already delivered yesterday.\n",
    "    \n",
    "    ARGUMENTS\n",
    "    headlines (list of str): Headlines from all sources\n",
    "    last_headlines_path (str): The full path on S3 for this subscriber's cache of yesterday's headlines\n",
    "    \n",
    "    RETURNS\n",
    "    fresh_headlines (list of str): Headlines except those we already delivered yesterday\n",
    "    \"\"\"\n",
    "    \n",
    "    with fs.open(last_headlines_path, \"r\") as f:\n",
    "        last_headlines = [line.strip() for line in f.readlines()]\n",
    "        logging.info(f\"Read last headlines from {last_headlines_path}\")\n",
    "    fresh_headlines = [headline for headline in headlines if headline not in last_headlines]\n",
    "    logging.info(f\"Removed repeat headlines: {[headline for headline in headlines if headline in last_headlines]}\") \n",
    "    return fresh_headlines\n",
    "\n",
    "\n",
    "def collect_all_headlines(sources):\n",
    "    \"\"\"Extract headlines from all sources we researched.\n",
    "    \n",
    "    ARGUMENTS\n",
    "    sources (list of dict): A list of sources and their headlines\n",
    "\n",
    "    RETURNS\n",
    "    headlines (list of str): Flat list of headlines retrieved from all sources\n",
    "    \n",
    "    \"\"\"\n",
    "    headlines_nested = [source[\"headlines\"] for source in sources if \"headlines\" in source and source[\"headlines\"]]\n",
    "    return [item for sublist in headlines_nested for item in sublist]\n",
    "\n",
    "\n",
    "def lower_list(l):\n",
    "    \"\"\"Helper function to lowercase the items in a list of strings.\n",
    "    \n",
    "    ARGUMENTS\n",
    "    l (list of str): A list of headlines\n",
    "    \n",
    "    RETURNS\n",
    "    l_lower (list of str): A list of lowercase headlines\n",
    "    \"\"\"\n",
    "    \n",
    "    if not l:\n",
    "        return None\n",
    "    return [item.lower() for item in l]\n",
    "\n",
    "\n",
    "def breaks_rule(headline, cant_begin_with, cant_contain, cant_end_with):\n",
    "    \"\"\"Evaluate whether a headline breaks any of the passed sets of editorial rules\n",
    "    \n",
    "    ARGUMENTS\n",
    "    headline (str): The text to evaluate\n",
    "    cant_begin_with (list of str): Text that a headline cannot start with\n",
    "    cant_contain (list of str): Text that cannot exist anywhere in a headline\n",
    "    cant_end_with (list of str): Text that a headline cannot end with\n",
    "    \n",
    "    RETURNS\n",
    "    True if this headline violates any rule\n",
    "    \"\"\"\n",
    "    \n",
    "    for phrase in cant_begin_with:\n",
    "        if headline.startswith(phrase):\n",
    "            return True\n",
    "    for phrase in cant_contain:\n",
    "        if phrase in headline:\n",
    "            return True\n",
    "    for phrase in cant_end_with:\n",
    "        if headline.endswith(phrase):\n",
    "            return True\n",
    "\n",
    "        \n",
    "def apply_substance_rules(headlines, substance_rules):\n",
    "    \"\"\"Remove headlines that fail our logic for ensuring a headline is substanative.\n",
    "\n",
    "    ARGUMENTS\n",
    "    headlines (list of str): The headlines retrieved from all sources\n",
    "    substance_rules (dict): The editorial rules, which consist of lists of phrases\n",
    "    \n",
    "    RETURNS\n",
    "    kept_headlines (list of str): The headlines that pass all substrance rules.\n",
    "\n",
    "    \"\"\"\n",
    "    cant_begin_with = lower_list(substance_rules.get(\"cant_begin_with\", []))\n",
    "    cant_contain = lower_list(substance_rules.get(\"cant_contain\", []))\n",
    "    cant_end_with = lower_list(substance_rules.get(\"cant_end_with\", []))\n",
    "    removed_headlines = [headline for headline in headlines if breaks_rule(headline.lower(), cant_begin_with, cant_contain, cant_end_with)]\n",
    "    logging.info(f\"Substance rules removed: {removed_headlines}\")\n",
    "    kept_headlines = [headline for headline in headlines if headline not in removed_headlines]\n",
    "    return kept_headlines \n",
    "\n",
    "\n",
    "def openai_chat_completion(gpt_config, message):\n",
    "    \"\"\"Make an API call to the OpenAI GPT chat endpoint.\n",
    "    \n",
    "    ARGUMENTS\n",
    "    gpt_config (dict): Parameters for using the API\n",
    "    message (str): The full prompt to send GPT, including generic lead-in, headlines, and instruction (customized to each subscriber)\n",
    "    \n",
    "    RETURNS\n",
    "    headlines_to_remove_str (string): GPT's response of which headlines to remove, in str format\n",
    "    \"\"\"\n",
    "    \n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=gpt_config[\"substance_filter_model\"],\n",
    "        messages=[\n",
    "            {\"role\":\"system\", \"content\": gpt_config[\"system_role\"]},\n",
    "            {\"role\": \"user\", \"content\": message}\n",
    "        ]\n",
    "    )\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "\n",
    "def apply_substance_filter_model(headlines, gpt_config, nba_teams=None):\n",
    "    \"\"\"Use LLM to remove headlines that don't say much useful.\n",
    "    \n",
    "    NOTE\n",
    "    Requires an OPENAI_API_KEY in AWS Secrets Manager.\n",
    "    \n",
    "    ARGUMENTS\n",
    "    headlines (list): List of string headlines, original candidates for the issue\n",
    "    gpt_config (dict): Configuration for editing headlines using GPT LLM through the Open AI API.\n",
    "    nba_teams (list): The names of NBA teams we're tracking, to ensure GPT doesn't cut those headlines. They're important!\n",
    "    \n",
    "    RETURNS\n",
    "    kept_headlines (list): The headlines that GPT did not remove\n",
    "    \"\"\"\n",
    "    \n",
    "    GPT_RETRY_SLEEP = 30\n",
    "    openai.api_key = get_fn_secret(\"OPENAI_API_KEY\")\n",
    "    headlines_for_gpt = [f\"* {headline}\" for headline in headlines]\n",
    "    lead_in = \"Here are today's news headlines:\"\n",
    "    message = lead_in + \"\\n\" + \"\\n\".join(headlines_for_gpt) + \"\\n\" + gpt_config[\"instruction\"]\n",
    "    try:\n",
    "        try:\n",
    "            headlines_to_remove_str = openai_chat_completion(gpt_config, message)\n",
    "        except openai.error.APIConnectionError:\n",
    "            logging.info(f\"OpenAI API error. Waiting {GPT_RETRY_SLEEP} secs, retrying...\")\n",
    "            sleep(GPT_RETRY_SLEEP)\n",
    "            headlines_to_remove_str = openai_chat_completion(gpt_config, message)\n",
    "            logging.info(f\"OpenAI API error. Waiting {GPT_RETRY_SLEEP} secs, retrying...\")\n",
    "            logging.info(\"Retry worked! 😅\")\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"OpenAI failed: {str(type(e))}, {str(e)}\")\n",
    "        headlines_to_remove_str = None\n",
    "\n",
    "    headlines_to_remove = [h for h in headlines_to_remove_str.split(\"\\n\")]\n",
    "    removed_headlines = [headline for headline in headlines if headline in headlines_to_remove] # Extra QC step to make sure GPT didn't return a hallucination that wasn't in headlines we sent it.\n",
    "    logging.info(f\"GPT removed: {removed_headlines}\") \n",
    "    return [headline for headline in headlines if headline not in removed_headlines]\n",
    "\n",
    "\n",
    "def clean_headline(headline):\n",
    "    \"\"\"Standardize text formatting of a headline string\n",
    "    \n",
    "    NOTE\n",
    "    - Assumes we have already stripped white space from beginning and end of headline\n",
    "    - We apply these steps before applying substance rules, which rely on standard format,\n",
    "    before checking if these headlines were in yesterday's issue, and before logging today's headlines.\n",
    "\n",
    "    ARGUMENTS\n",
    "    headline (str): A single headline.\n",
    "    \n",
    "    RETURNS\n",
    "    headline (str): A single, clean headline.\n",
    "    \"\"\" \n",
    "    \n",
    "    headline = headline.replace(\"’\",\"'\").replace(\"‘\",\"'\") # Standardize apostrophe characters\n",
    "    # Ensure all have trailing period\n",
    "    return headline + \".\" if not headline.endswith(\".\") and not headline.endswith(\"?\") else headline \n",
    "\n",
    "\n",
    "def edit_headlines(raw_headlines, editorial_policies, gpt_config=None):\n",
    "    \"\"\"Apply all editorial policies to the headlines.\n",
    "    \n",
    "    ARGUMENTS\n",
    "    raw_headlines (list): List of string headlines, original candidates for the issue\n",
    "    editorial_policies (dict): Rules and preferences from this user/issue's config\n",
    "    gpt_config (dict): Configuration for editing headlines using GPT LLM through the Open AI API.\n",
    "    \n",
    "    RETURNS\n",
    "    edited_headlines (list): Headlines after filtering ones that violate editorial policies\n",
    "    \"\"\"\n",
    "    \n",
    "    edited_headlines = [clean_headline(headline) for headline in raw_headlines]  \n",
    "    if \"one_headline_keywords\" in editorial_policies:\n",
    "        edited_headlines = limit_one_headline_keywords(edited_headlines, editorial_policies[\"one_headline_keywords\"])\n",
    "    edited_headlines = remove_repeat_headlines(edited_headlines, editorial_policies[\"last_headlines_path\"])\n",
    "    if edited_headlines:\n",
    "        edited_headlines = apply_substance_rules(edited_headlines, editorial_policies[\"substance_rules\"])\n",
    "        if gpt_config:\n",
    "            edited_headlines = apply_substance_filter_model(edited_headlines, gpt_config)\n",
    "        else:\n",
    "            logging.info(\"Did not apply GPT substance model. no gpt_config\")\n",
    "            pass\n",
    "    logging.info(\"Edited headlines: \" + str(edited_headlines))\n",
    "    return edited_headlines\n",
    "\n",
    "\n",
    "def edit_nba_headlines(nba_headlines, nba_teams):\n",
    "    \"\"\"Clean and harmonize NBA game headlines. The key outcome: when two of our tracked teams are playing each other, only report once, not twice.\n",
    "    \n",
    "    ARGUMENTS\n",
    "    nba_headlines (list of str): News related to today's NBA game(s) for tracked teams\n",
    "    nba_teams (list of str): The names of the tracked teams that may be in the headlines.\n",
    "    \n",
    "    RETURNS\n",
    "    cleaned_headlines (list of str): Harmonized news about today's NBA game(s)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Avoid [None] lists\n",
    "    nba_headlines = [h for h in nba_headlines if h] \n",
    "\n",
    "    # If two tracked teams are playing each other, only give one headline\n",
    "    cleaned_headlines = []\n",
    "    teams_already_reported = set()\n",
    "    for headline in nba_headlines:\n",
    "        teams_found = {t for t in nba_teams if t in headline}\n",
    "        if not teams_already_reported.intersection(teams_found):\n",
    "            cleaned_headlines.append(headline)\n",
    "        teams_already_reported.update(teams_found) \n",
    "    return cleaned_headlines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae149e5-00b7-4a3e-9bf0-5cf467752901",
   "metadata": {},
   "source": [
    "## 🎨 Design\n",
    "Lay out the email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ec37521-c650-4e2b-ae4d-2dbd40446ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_issue(\n",
    "    issue_config,\n",
    "    headlines,\n",
    "    arts_headlines,\n",
    "    images,\n",
    "    log_stream\n",
    "):\n",
    "    \"\"\"Organize the final content as HTML for one subscriber's issue.\n",
    "    \n",
    "    ARGUMENTS\n",
    "    issue_config (dict): The settings for the issue\n",
    "    headlines (list of str): The final news headlines to be reported in this issue\n",
    "    arts_headlines (list of str): Optional, the final arts headlines to be reported in this issue\n",
    "    images (list): Optional, images to attach to the image\n",
    "    log_stream (String IO): Optional, the log report from running Finite News\n",
    "    \n",
    "    RETURNS\n",
    "    html (str): The Finite News template populated with the final content\n",
    "    \"\"\"\n",
    "    \n",
    "    html = issue_config[\"layout\"][\"template_html\"]\n",
    "    html = html.replace(\"[[LOGO_URL]]\", issue_config[\"layout\"][\"logo_url\"])\n",
    "    slogans = issue_config.get(\"slogans\", [''])\n",
    "    html = html.replace(\"[[SLOGAN]]\", choice(slogans))\n",
    "\n",
    "    headlines_html = [f\"<li>{headline}</li>\" for headline in headlines]\n",
    "    headlines_html = \"\".join(headlines_html)\n",
    "    if headlines_html:\n",
    "        headlines_block = f\"<ul>{headlines_html}</ul>\"\n",
    "    else:\n",
    "        headlines_block = \"<p>🦗 chirp...chirp... no new headlines since last issue🦗\"\n",
    "    html = html.replace(\"[[HEADLINES_BLOCK]]\", headlines_block)\n",
    "\n",
    "    if arts_headlines:\n",
    "        arts_headlines_html = [f\"<li>{headline}</li>\" for headline in arts_headlines]\n",
    "        arts_headlines_html = \"\".join(arts_headlines_html)\n",
    "        if arts_headlines_html:\n",
    "            arts_headlines_block = f\"<h3>🖼️ The Arts</h3><ul>{arts_headlines_html}</ul>\"\n",
    "        else:\n",
    "            arts_headlines_block = \"\"\n",
    "    else: \n",
    "        arts_headlines_block = \"\"\n",
    "    html = html.replace(\"[[ARTS_BLOCK]]\", arts_headlines_block)\n",
    "\n",
    "    forecast=issue_config[\"nws\"].get(\"forecast\", None)\n",
    "    if forecast:\n",
    "        weather_emoji = get_weather_emoji(forecast[\"short\"])\n",
    "        weather_block = f\"<h3>{weather_emoji} {forecast['short']}</h3><img src={forecast['icon_url']} alt='Forecast icon'><br><p>{forecast['detailed']}</p>\"\n",
    "    else:\n",
    "        weather_block = \"\"\n",
    "    html = html.replace(\"[[WEATHER_BLOCK]]\", weather_block)\n",
    "\n",
    "    if images:\n",
    "        images_block = \"\".join([f\"<img src='cid:image_{i}', alt='image_{i}'><br>\" for i in range(0,len(images))])\n",
    "    else:\n",
    "        images_block = \"\"\n",
    "    html = html.replace(\"[[IMAGES_BLOCK]]\", images_block)\n",
    "    \n",
    "    if issue_config[\"editorial\"][\"add_car_talk_credit\"]:\n",
    "        car_talk_block = \"<p>\" + get_car_talk_credit(issue_config[\"bucket_path\"]) + \"</p><br>\"\n",
    "    else:\n",
    "        car_talk_block = \"\"\n",
    "    html = html.replace(\"[[CAR_TALK_CREDIT]]\",car_talk_block)\n",
    "\n",
    "    try:\n",
    "        thoughts_of_the_day=issue_config.get(\"thoughts_of_the_day\", [''])\n",
    "        html = html.replace(\"[[THOUGHT_OF_THE_DAY]]\", choice(thoughts_of_the_day))\n",
    "    except TypeError as e:\n",
    "        logging.warning(f\"TypeError on replace closing thoughts. Yaml malfored?: {e}. thoughts_of_the_day type: {type(thoughts_of_the_day)}. Expected string. {thoughts_of_the_day}\")\n",
    "        html = html.replace(\"[[THOUGHT_OF_THE_DAY]]\",\"\")\n",
    "\n",
    "    attributions=get_attributions(\n",
    "        headline_sources=issue_config[\"news_sources\"] + issue_config[\"arts_sources\"],\n",
    "        nba_used=issue_config[\"nba_teams\"],\n",
    "        nws_used=issue_config[\"nws\"].get(\"forecast\", None)\n",
    "    )\n",
    "    html = html.replace(\"[[ATTRIBUTIONS]]\", attributions)\n",
    "\n",
    "    if issue_config[\"admin\"]: # Append exceptions from logging to email\n",
    "        log_items = [l for l in log_stream.getvalue().split(\"\\n\") if len(l)>0]\n",
    "        if log_items:\n",
    "            log_items_html = \"\".join([f\"<li><i>{log_item}</i></li>\" for log_item in log_items])\n",
    "            logging_block = f\"<h3>👾 Logs</h3><ul>{log_items_html}</ul>\"\n",
    "        else:\n",
    "            logging_block = \"\"\n",
    "    else:\n",
    "        logging_block = \"\"\n",
    "    html = html.replace(\"[[LOGGING_BLOCK]]\", logging_block)\n",
    "\n",
    "    return html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd77b956-f623-4659-bbe1-25a231789ee2",
   "metadata": {},
   "source": [
    "## 📰 Publishing\n",
    "Orchestrate and deliver the news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d5edaf8-9f09-4528-bc6a-64de2778c024",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def email_issue(sender, subscriber_email, html, images):\n",
    "    \"\"\"Send issue of Finite News to a subscriber by email using the SendGrid API service.\n",
    "    \n",
    "    NOTE\n",
    "    Requires a secret in AWS Secret Manager for SENDGRID_API_KEY\n",
    "    \n",
    "    ARGUMENTS\n",
    "    sender (dict): Metadata about the email source, with keys for \"subject\" and \"email\"\n",
    "    subscriber_email (str): The email address for the destination\n",
    "    html (str): The issue content\n",
    "    images (list): Optional, png images to attach to the email\n",
    "    \n",
    "    RETURNS\n",
    "    None\n",
    "    \"\"\"\n",
    "    \n",
    "    brand = sender[\"subject\"]\n",
    "    today = date.today().strftime(\"%m.%d.%y\").lstrip(\"0\")\n",
    "    message = Mail(\n",
    "    from_email=sender[\"email\"],\n",
    "    to_emails=subscriber_email,\n",
    "    subject=f\"{brand} for {today}\",\n",
    "    html_content=html)\n",
    "    attachments = []\n",
    "    for i, image in enumerate(images):\n",
    "        attachedFile = Attachment(\n",
    "            disposition='inline',\n",
    "            file_name=f'image_{i}.png',\n",
    "            file_type='image/png',\n",
    "            file_content=image,\n",
    "            content_id=f'image_{i}',\n",
    "        )\n",
    "        attachments.append(attachedFile)\n",
    "    message.attachment = attachments\n",
    "    try:\n",
    "        sendgrid_key = get_fn_secret('SENDGRID_API_KEY')\n",
    "        sg = SendGridAPIClient(sendgrid_key)\n",
    "        response = sg.send(message)\n",
    "        if response.status_code==202:\n",
    "            logging.info(f\"{subscriber_email}: Extry extry! Email is away!\")\n",
    "    except Exception as e:\n",
    "        logging.critical(f\"{subscriber_email}: Error in send_email: {str(type(e))}, {str(e)}\") # Admin issue will get this logging line in its email about failures in prior, non-admin issues.\n",
    "\n",
    "        \n",
    "def write_issue_to_file(subscriber_name, html):\n",
    "    \"\"\"Append issue html to local .txt file of day's issues, creating file if it doesn't exist.\n",
    "    \n",
    "    ARGUMENTS\n",
    "    subscriber_name (str): The name (or email address) of the issue's recipient, to categorize a day's issues\n",
    "    html (str): The content of the issue\n",
    "    \n",
    "    RETURNS\n",
    "    None\n",
    "    \n",
    "    \"\"\"\n",
    "    with open(f\"issues_for_{datetime.now().strftime('%m-%d-%y')}.txt\", \"a\") as f:\n",
    "        f.write(f\"\"\"{subscriber_name}\\n{datetime.now().strftime('%m-%d-%y %H:%M:%S')}\\n{html}\\n--------------------------------------------\\n\"\"\")\n",
    "    logging.info(f\"{subscriber_name}: Extry extry! Wrote to text file.\")\n",
    "\n",
    "\n",
    "def deliver_issue(issue_config, html, images):\n",
    "    \"\"\"Send the content of Finite News to one subscriber by the selected method\n",
    "\n",
    "    ARGUMENTS\n",
    "    issue_config (dict): The settings for the issue\n",
    "    html (str): The content of the email formatted for the email\n",
    "    images (list): Optional, images to attach to the image\n",
    "    \n",
    "    RETURNS\n",
    "    None\n",
    "    \"\"\"\n",
    "    logging.info(f\"{issue_config['subscriber_email']}: Starting deliver_issue()\")\n",
    "    if issue_config[\"email_delivery\"]:\n",
    "        email_issue(issue_config[\"sender\"], issue_config[\"subscriber_email\"], html, images)\n",
    "    else: \n",
    "        write_issue_to_file(subscriber_name=issue_config[\"subscriber_email\"], html=html)\n",
    "\n",
    "\n",
    "def create_issue(issue_config, log_stream):   \n",
    "    \"\"\"Populate the content of Finite News customized for one subscriber\n",
    "    \n",
    "    ARGUMENTS\n",
    "    issue_config (dict): The settings for the issue\n",
    "    log_stream (StringIO object): In-memory file-like object that collects results from logging during the Finite News run\n",
    "    \n",
    "    RETURNS\n",
    "    html (str): The content of the email formatted for the email\n",
    "    images (list): Optional, images to attach to the image\n",
    "    \"\"\"    \n",
    "    \n",
    "    logging.info(f\"{issue_config['subscriber_email']}: Starting create_issue()\")\n",
    "    \n",
    "    # Get tonight's NBA games for tracked teams\n",
    "    if issue_config[\"nba_teams\"]:\n",
    "        nba_headlines = [get_todays_nba_game(nba_team) for nba_team in issue_config[\"nba_teams\"]]\n",
    "        nba_headlines = edit_nba_headlines(nba_headlines, issue_config[\"nba_teams\"])\n",
    "    else:\n",
    "        nba_headlines = []\n",
    "\n",
    "    # Get News headlines\n",
    "    news_sources = research_sources([source for source in issue_config[\"news_sources\"]])\n",
    "    news_headlines = nba_headlines + collect_all_headlines(news_sources)\n",
    "    original_headlines = news_headlines # Before removing repeats or applying substance filters (some are nondeterministic)\n",
    "    news_headlines = edit_headlines(\n",
    "        raw_headlines=news_headlines,\n",
    "        editorial_policies=issue_config[\"editorial\"],\n",
    "        gpt_config = issue_config[\"gpt\"]\n",
    "    )\n",
    "    \n",
    "    # Get Arts News, if requested\n",
    "    if len(issue_config[\"arts_sources\"])>0:\n",
    "        arts_sources = research_sources([source for source in issue_config[\"arts_sources\"]])\n",
    "        arts_headlines = collect_all_headlines(arts_sources)\n",
    "        original_headlines += arts_headlines \n",
    "        arts_headlines = edit_headlines(\n",
    "            raw_headlines=arts_headlines,\n",
    "            editorial_policies=issue_config[\"editorial\"],\n",
    "            gpt_config = issue_config[\"gpt\"]\n",
    "        )\n",
    "    else:\n",
    "        arts_headlines = []\n",
    "\n",
    "    if issue_config[\"editorial\"][\"log_today_headlines\"]==True: \n",
    "        log_headlines(original_headlines, issue_config[\"editorial\"][\"last_headlines_path\"])\n",
    "    if \"nws\" in issue_config:\n",
    "        issue_config[\"nws\"][\"forecast\"] = get_forecast(issue_config[\"nws\"])\n",
    "    images = get_screenshots([source for source in news_sources if source[\"type\"]==\"screenshot\"])\n",
    "    html = format_issue(issue_config, news_headlines, arts_headlines, images, log_stream)\n",
    "    logging.info(f\"{issue_config['subscriber_email']}: Finished create_issue()\")\n",
    "    return html, images\n",
    "\n",
    "\n",
    "def run_finite_news(dev_mode, disable_gpt, logging_level=logging.WARNING):\n",
    "    \"\"\"Entry point to create and deliver all of today's issues of Finite News.\n",
    "\n",
    "    ARGUMENTS\n",
    "    dev_mode (bool): If True we're in development or debug mode, so don't send emails or modify headline_logs.\n",
    "    disable_gpt (bool): If True, don't call the GPT API and incur costs, for example during dev or debug cycles.\n",
    "    logging_level (level from logging library): The deepest granularity of log messages to track\n",
    "    \n",
    "    RETURNS\n",
    "    None\n",
    "    \"\"\"\n",
    "    \n",
    "    log_stream = init_logging(logging_level)\n",
    "    for subscriber_config in load_subscriber_configs(dev_mode, disable_gpt):\n",
    "        try:\n",
    "            html, images = create_issue(subscriber_config, log_stream)\n",
    "            deliver_issue(subscriber_config, html, images)\n",
    "        except Exception as e:\n",
    "            logging.critical(f\"{subscriber_config['subscriber_email']}: Issue failed due to unhandled exception: {str(type(e))}, {str(e)}\")\n",
    "    print(\"👍\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9f8abf-e7f0-401e-8a8c-134fca5dae0c",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "944739db-fe88-437e-8113-118ce4cb0ede",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "👍\n"
     ]
    }
   ],
   "source": [
    "run_finite_news(DEV_MODE, DISABLE_GPT, LOGGING_LEVEL)"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 2.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc-autonumbering": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
